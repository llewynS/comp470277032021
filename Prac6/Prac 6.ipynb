{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "correct-hindu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.8.1+cpu in c:\\users\\llewyn\\code\\comp470277032021\\machine_learning\\lib\\site-packages (1.8.1+cpu)\n",
      "Requirement already satisfied: torchvision==0.9.1+cpu in c:\\users\\llewyn\\code\\comp470277032021\\machine_learning\\lib\\site-packages (0.9.1+cpu)\n",
      "Requirement already satisfied: torchaudio===0.8.1 in c:\\users\\llewyn\\code\\comp470277032021\\machine_learning\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\llewyn\\code\\comp470277032021\\machine_learning\\lib\\site-packages (from torch==1.8.1+cpu) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\llewyn\\code\\comp470277032021\\machine_learning\\lib\\site-packages (from torch==1.8.1+cpu) (1.20.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\llewyn\\code\\comp470277032021\\machine_learning\\lib\\site-packages (from torchvision==0.9.1+cpu) (8.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.8.1+cpu torchvision==0.9.1+cpu torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "described-living",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "opening-threshold",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "promotional-domain",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, D_in, D_out, act_out, act, layers:list):\n",
    "        super().__init__()\n",
    "        #Flatten input to 1D \n",
    "        self.layers = [torch.nn.Flatten()]\n",
    "        #Create input W and b\n",
    "        self.act_linear(D_in, layers[0], act)\n",
    "        #Create hidden layer W and b\n",
    "        for i in range(1,len(layers)):\n",
    "            self.act_linear(layers[i-1], layers[i], act)\n",
    "        #Create output W and b\n",
    "        self.act_linear(layers[-1], D_out, act_out)\n",
    "        self.layer_stack = torch.nn.Sequential(*self.layers)\n",
    "    \n",
    "    def act_linear(self, _in, out, act):\n",
    "        self.layers += [torch.nn.Linear(_in, out), act()]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "concrete-perception",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(28*28,10,torch.nn.LeakyReLU,torch.nn.LeakyReLU,[256,128,64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "integral-feeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "reliable-village",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.701214  [    0/60000]\n",
      "loss: 0.663820  [ 6400/60000]\n",
      "loss: 0.466953  [12800/60000]\n",
      "loss: 0.537046  [19200/60000]\n",
      "loss: 0.490364  [25600/60000]\n",
      "loss: 0.469752  [32000/60000]\n",
      "loss: 0.388410  [38400/60000]\n",
      "loss: 0.596348  [44800/60000]\n",
      "loss: 0.498440  [51200/60000]\n",
      "loss: 0.514771  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.006844 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.280278  [    0/60000]\n",
      "loss: 0.373239  [ 6400/60000]\n",
      "loss: 0.299591  [12800/60000]\n",
      "loss: 0.392997  [19200/60000]\n",
      "loss: 0.405260  [25600/60000]\n",
      "loss: 0.390431  [32000/60000]\n",
      "loss: 0.327137  [38400/60000]\n",
      "loss: 0.482946  [44800/60000]\n",
      "loss: 0.461531  [51200/60000]\n",
      "loss: 0.424404  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.006397 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.216297  [    0/60000]\n",
      "loss: 0.345657  [ 6400/60000]\n",
      "loss: 0.236607  [12800/60000]\n",
      "loss: 0.320957  [19200/60000]\n",
      "loss: 0.351551  [25600/60000]\n",
      "loss: 0.351001  [32000/60000]\n",
      "loss: 0.289798  [38400/60000]\n",
      "loss: 0.421448  [44800/60000]\n",
      "loss: 0.371681  [51200/60000]\n",
      "loss: 0.371912  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.006020 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.187598  [    0/60000]\n",
      "loss: 0.330462  [ 6400/60000]\n",
      "loss: 0.219531  [12800/60000]\n",
      "loss: 0.294128  [19200/60000]\n",
      "loss: 0.330632  [25600/60000]\n",
      "loss: 0.359603  [32000/60000]\n",
      "loss: 0.295432  [38400/60000]\n",
      "loss: 0.375311  [44800/60000]\n",
      "loss: 0.348500  [51200/60000]\n",
      "loss: 0.330233  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.005873 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.210064  [    0/60000]\n",
      "loss: 0.323657  [ 6400/60000]\n",
      "loss: 0.201091  [12800/60000]\n",
      "loss: 0.259963  [19200/60000]\n",
      "loss: 0.380720  [25600/60000]\n",
      "loss: 0.364712  [32000/60000]\n",
      "loss: 0.270694  [38400/60000]\n",
      "loss: 0.429778  [44800/60000]\n",
      "loss: 0.321617  [51200/60000]\n",
      "loss: 0.280995  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.005554 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.196448  [    0/60000]\n",
      "loss: 0.296639  [ 6400/60000]\n",
      "loss: 0.190080  [12800/60000]\n",
      "loss: 0.230828  [19200/60000]\n",
      "loss: 0.370573  [25600/60000]\n",
      "loss: 0.341542  [32000/60000]\n",
      "loss: 0.233455  [38400/60000]\n",
      "loss: 0.351219  [44800/60000]\n",
      "loss: 0.328949  [51200/60000]\n",
      "loss: 0.255217  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.005458 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.182709  [    0/60000]\n",
      "loss: 0.294170  [ 6400/60000]\n",
      "loss: 0.193215  [12800/60000]\n",
      "loss: 0.216240  [19200/60000]\n",
      "loss: 0.363832  [25600/60000]\n",
      "loss: 0.323468  [32000/60000]\n",
      "loss: 0.200674  [38400/60000]\n",
      "loss: 0.372945  [44800/60000]\n",
      "loss: 0.328184  [51200/60000]\n",
      "loss: 0.253596  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.005454 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.167439  [    0/60000]\n",
      "loss: 0.300992  [ 6400/60000]\n",
      "loss: 0.179936  [12800/60000]\n",
      "loss: 0.213720  [19200/60000]\n",
      "loss: 0.369652  [25600/60000]\n",
      "loss: 0.300968  [32000/60000]\n",
      "loss: 0.186380  [38400/60000]\n",
      "loss: 0.316300  [44800/60000]\n",
      "loss: 0.308796  [51200/60000]\n",
      "loss: 0.301451  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.005448 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.168527  [    0/60000]\n",
      "loss: 0.279233  [ 6400/60000]\n",
      "loss: 0.169975  [12800/60000]\n",
      "loss: 0.192370  [19200/60000]\n",
      "loss: 0.293295  [25600/60000]\n",
      "loss: 0.287913  [32000/60000]\n",
      "loss: 0.181069  [38400/60000]\n",
      "loss: 0.299689  [44800/60000]\n",
      "loss: 0.303810  [51200/60000]\n",
      "loss: 0.242590  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.005491 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.182957  [    0/60000]\n",
      "loss: 0.260575  [ 6400/60000]\n",
      "loss: 0.210201  [12800/60000]\n",
      "loss: 0.202507  [19200/60000]\n",
      "loss: 0.451059  [25600/60000]\n",
      "loss: 0.273681  [32000/60000]\n",
      "loss: 0.237386  [38400/60000]\n",
      "loss: 0.294332  [44800/60000]\n",
      "loss: 0.283899  [51200/60000]\n",
      "loss: 0.223471  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.005645 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train_dataloader = torch.utils.data.DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-punishment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
